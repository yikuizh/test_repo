{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c775a80e",
   "metadata": {},
   "source": [
    "# Bioclimatic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad03ea7",
   "metadata": {},
   "source": [
    "Compute the bioclimatic variables as defined in https://pubs.usgs.gov/ds/691/ds691.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709f304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b7d8ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine zarr must be one of: ['store']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/zhang/script/bioclim_vars.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdwd_datacube_intern_3/home/zhang/script/bioclim_vars.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dsspat \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39;49mopen_zarr(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/DWDCube/cube_spatial.zarr/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdwd_datacube_intern_3/home/zhang/script/bioclim_vars.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dstime \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_zarr(\u001b[39m\"\u001b[39m\u001b[39mhttps://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/DWDCube/cube_temporal.zarr/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdwd_datacube_intern_3/home/zhang/script/bioclim_vars.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m subset \u001b[39m=\u001b[39m dstime\u001b[39m.\u001b[39misel(Time\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m365\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m#two year subset for faster testing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_cube/lib/python3.12/site-packages/xarray/backends/zarr.py:867\u001b[0m, in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    854\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mopen_zarr() got unexpected keyword arguments \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(kwargs\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    855\u001b[0m     )\n\u001b[1;32m    857\u001b[0m backend_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    858\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msynchronizer\u001b[39m\u001b[39m\"\u001b[39m: synchronizer,\n\u001b[1;32m    859\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconsolidated\u001b[39m\u001b[39m\"\u001b[39m: consolidated,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzarr_version\u001b[39m\u001b[39m\"\u001b[39m: zarr_version,\n\u001b[1;32m    865\u001b[0m }\n\u001b[0;32m--> 867\u001b[0m ds \u001b[39m=\u001b[39m open_dataset(\n\u001b[1;32m    868\u001b[0m     filename_or_obj\u001b[39m=\u001b[39;49mstore,\n\u001b[1;32m    869\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    870\u001b[0m     decode_cf\u001b[39m=\u001b[39;49mdecode_cf,\n\u001b[1;32m    871\u001b[0m     mask_and_scale\u001b[39m=\u001b[39;49mmask_and_scale,\n\u001b[1;32m    872\u001b[0m     decode_times\u001b[39m=\u001b[39;49mdecode_times,\n\u001b[1;32m    873\u001b[0m     concat_characters\u001b[39m=\u001b[39;49mconcat_characters,\n\u001b[1;32m    874\u001b[0m     decode_coords\u001b[39m=\u001b[39;49mdecode_coords,\n\u001b[1;32m    875\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzarr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    876\u001b[0m     chunks\u001b[39m=\u001b[39;49mchunks,\n\u001b[1;32m    877\u001b[0m     drop_variables\u001b[39m=\u001b[39;49mdrop_variables,\n\u001b[1;32m    878\u001b[0m     chunked_array_type\u001b[39m=\u001b[39;49mchunked_array_type,\n\u001b[1;32m    879\u001b[0m     from_array_kwargs\u001b[39m=\u001b[39;49mfrom_array_kwargs,\n\u001b[1;32m    880\u001b[0m     backend_kwargs\u001b[39m=\u001b[39;49mbackend_kwargs,\n\u001b[1;32m    881\u001b[0m     decode_timedelta\u001b[39m=\u001b[39;49mdecode_timedelta,\n\u001b[1;32m    882\u001b[0m     use_cftime\u001b[39m=\u001b[39;49muse_cftime,\n\u001b[1;32m    883\u001b[0m     zarr_version\u001b[39m=\u001b[39;49mzarr_version,\n\u001b[1;32m    884\u001b[0m )\n\u001b[1;32m    885\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/data_cube/lib/python3.12/site-packages/xarray/backends/api.py:552\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m from_array_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m     from_array_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 552\u001b[0m backend \u001b[39m=\u001b[39m plugins\u001b[39m.\u001b[39;49mget_backend(engine)\n\u001b[1;32m    554\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    555\u001b[0m     decode_cf,\n\u001b[1;32m    556\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m overwrite_encoded_chunks \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39moverwrite_encoded_chunks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_cube/lib/python3.12/site-packages/xarray/backends/plugins.py:205\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    203\u001b[0m     engines \u001b[39m=\u001b[39m list_engines()\n\u001b[1;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m engines:\n\u001b[0;32m--> 205\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munrecognized engine \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m must be one of: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(engines)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m     backend \u001b[39m=\u001b[39m engines[engine]\n\u001b[1;32m    209\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(engine, \u001b[39mtype\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine zarr must be one of: ['store']"
     ]
    }
   ],
   "source": [
    "dsspat = xr.open_zarr(\"https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/DWDCube/cube_spatial.zarr/\")\n",
    "dstime = xr.open_zarr(\"https://openstack.cebitec.uni-bielefeld.de:8080/swift/v1/DWDCube/cube_temporal.zarr/\")\n",
    "subset = dstime.isel(Time=range(0, 2*365+1)) #two year subset for faster testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8216152",
   "metadata": {},
   "source": [
    "# Intermediate variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e4713",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly max:\n",
    "if isfile(\"./datasets/tas_mmax.nc\"):\n",
    "    tas_mmax = xr.open_dataarray(\"./datasets/tas_mmax.nc\")\n",
    "else:\n",
    "    tas_mmax = dstime[\"tas\"].resample(Time=\"1MS\").max(dim=\"Time\")\n",
    "    tas_mmax.to_netcdf(\"./datasets/tas_mmax.nc\")\n",
    "    \n",
    "    \n",
    "# Monthly min:\n",
    "if isfile(\"./datasets/tas_mmin.nc\"):\n",
    "    tas_mmin = xr.open_dataarray(\"./datasets/tas_mmin.nc\")\n",
    "else:\n",
    "    tas_mmin = dstime[\"tas\"].resample(Time=\"1MS\").min(dim=\"Time\")\n",
    "    tas_mmin.to_netcdf(\"./datasets/tas_mmin.nc\")\n",
    "    \n",
    "    \n",
    "# Monthly mean:\n",
    "if isfile(\"./datasets/tas_mmean.nc\"):\n",
    "    tas_mmean = xr.open_dataarray(\"./datasets/tas_mmean.nc\")\n",
    "else:\n",
    "    tas_mmean = dstime[\"tas\"].resample(Time=\"1MS\").mean(dim=\"Time\")\n",
    "    tas_mmean.to_netcdf(\"./datasets/tas_mmean.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39cadb3",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly total:\n",
    "if isfile(\"./datasets/prec_mtot.nc\"):\n",
    "    prec_mtot = xr.open_dataarray(\"./datasets/prec_mtot.nc\")\n",
    "else:\n",
    "    prec_mtot = dstime[\"pr\"].resample(Time=\"1MS\").sum(dim=\"Time\") * 86400 #convert from flux to total in mm\n",
    "    prec_mtot = prec_mtot.assign_attrs({\"standard_name\": \"total_precipitation\", \"units\": \"mm\"})\n",
    "    prec_mtot.to_netcdf(\"./datasets/prec_mtot.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed134fa",
   "metadata": {},
   "source": [
    "# [BIO1] Annual Mean Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio1 = dstime[\"tas\"].groupby(\"Time.year\").mean(\"Time\")\n",
    "ds_bio1.to_netcdf(\"./datasets/bio1.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854afc7",
   "metadata": {},
   "source": [
    "# [BIO2] Mean Diurnal Range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd74563",
   "metadata": {},
   "source": [
    "The mean diurnal range is defined as mean of monthly maximum temperatures and minimum temperatures, i.e.: MDR $= \\frac{1}{12} \\sum_{i=1}^{12} T_\\text{max} - T_\\text{min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ad3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_range = tas_mmax - tas_mmin\n",
    "\n",
    "ds_bio2 = monthly_range.groupby(\"Time.year\").mean(dim=\"Time\")\n",
    "ds_bio2.to_netcdf(\"./datasets/bio2.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c1f0c5",
   "metadata": {},
   "source": [
    "# [BIO4] Temperature Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1ad50",
   "metadata": {},
   "source": [
    "Temperature seasonality is defined as the standard deviation (over one year) of monthly temperature averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio4 = tas_mmean.groupby(\"Time.year\").std(dim=\"Time\")\n",
    "ds_bio4.to_netcdf(\"./datasets/bio4.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03083e9c",
   "metadata": {},
   "source": [
    "# [BIO5] Max Temperature of Warmest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio5 = tas_mmax.groupby(\"Time.year\").max(dim=\"Time\")\n",
    "ds_bio5.to_netcdf(\"./datasets/bio5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c3bea",
   "metadata": {},
   "source": [
    "# [BIO6] Min Temperature of Coldest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio6 = tas_mmin.groupby(\"Time.year\").min(dim=\"Time\")\n",
    "ds_bio6.to_netcdf(\"./datasets/bio6.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba612c26",
   "metadata": {},
   "source": [
    "# [BIO7] Temperature Annual Range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbf08c",
   "metadata": {},
   "source": [
    "Defined as: $\\text{BIO5} - \\text{BIO6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf54e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio7 = ds_bio5 - ds_bio6\n",
    "ds_bio7.to_netcdf(\"./datasets/bio7.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde04b4f",
   "metadata": {},
   "source": [
    "# [BIO3] Isothermality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f014e",
   "metadata": {},
   "source": [
    "Defined as: $\\frac{\\text{BIO2}}{\\text{BIO7}} \\cdot 100$\\\n",
    "Execute below cell only after computing BIO7..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio3 = ds_bio2 / ds_bio7 * 100.\n",
    "ds_bio3.to_netcdf(\"./datasets/bio3.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a6f92",
   "metadata": {},
   "source": [
    "# [BIO8/10] Mean Temperature of Wettest/Driest Quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116342c3",
   "metadata": {},
   "source": [
    "In our [reference](https://pubs.usgs.gov/ds/691/ds691.pdf), the quartals are defined as 12 rolling three month windows looking forward, i.e., Jan-Feb-Mar, Feb-Mar-Apr, ..., Okt-Nov-Dec, Nov-Dec-Jan, Dec-Jan-Feb (12 in total). Annoyingly, xarrays rolling functionality only does backwards or centered rolling windows, which is why we have to loop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio8 = []\n",
    "ds_bio9 = []\n",
    "\n",
    "for year in set(dstime[\"Time.year\"].values):\n",
    "    tas_quarterly = [] #mean\n",
    "    precip_quarterly = [] #total\n",
    "    \n",
    "    # For each year loop through all the quarters as defined above:\n",
    "    start_dates = np.arange(np.datetime64(f\"{year}-01\"), np.datetime64(f\"{year+1}-01\"), np.timedelta64(1, \"M\"))\n",
    "    for start_date in start_dates:\n",
    "        slice_quart = slice(start_date, start_date + np.timedelta64(2, \"M\")) #quarter as time slice\n",
    "        \n",
    "        tas_quarterly.append(tas_mmean.sel(Time=slice_quart).mean(dim=\"Time\")) #mean temperature per grid point\n",
    "        precip_quarterly.append(prec_mtot.sel(Time=slice_quart).sum(dim=\"Time\")) #total precipitation per grid point\n",
    "    \n",
    "    # Get indices of wettest quarters this year:\n",
    "    precip_quarterly = xr.concat(precip_quarterly, dim=\"Quarter\")\n",
    "    wettest_quarters = precip_quarterly.argmax(dim=\"Quarter\")\n",
    "    driest_quarters = precip_quarterly.argmin(dim=\"Quarter\")\n",
    "    \n",
    "    # Get mean temperatures in wettest/driest quarters:\n",
    "    tas_quarterly = xr.concat(tas_quarterly, dim=\"Quarter\")\n",
    "    ds_bio8.append(tas_quarterly.isel(Quarter=wettest_quarters))\n",
    "    ds_bio9.append(tas_quarterly.isel(Quarter=wettest_quarters))\n",
    "    \n",
    "    \n",
    "# Save:\n",
    "ds_bio8 = xr.concat(ds_bio8, dim=\"year\")\n",
    "ds_bio8.to_netcdf(\"./datasets/bio8.nc\")\n",
    "\n",
    "ds_bio9 = xr.concat(ds_bio9, dim=\"year\")\n",
    "ds_bio9.to_netcdf(\"./datasets/bio9.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906655f3",
   "metadata": {},
   "source": [
    "# [BIO10/11] Mean Temperature of Warmest/Coldest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97300a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio10 = []\n",
    "ds_bio11 = []\n",
    "\n",
    "for year in set(dstime[\"Time.year\"].values):\n",
    "    tas_quarterly = [] #mean\n",
    "    \n",
    "    # For each year loop through all the quarters as defined in description of BIO8:\n",
    "    start_dates = np.arange(np.datetime64(f\"{year}-01\"), np.datetime64(f\"{year+1}-01\"), np.timedelta64(1, \"M\"))\n",
    "    for start_date in start_dates:\n",
    "        slice_quart = slice(start_date, start_date + np.timedelta64(2, \"M\")) #quarter as time slice\n",
    "        \n",
    "        tas_quarterly.append(tas_mmean.sel(Time=slice_quart).mean(dim=\"Time\")) #mean temperature per grid point\n",
    "        \n",
    "    ds_bio10.append(xr.concat(tas_quarterly, dim=\"Quarter\").max(dim=\"Quarter\"))\n",
    "    ds_bio11.append(xr.concat(tas_quarterly, dim=\"Quarter\").min(dim=\"Quarter\"))\n",
    "    \n",
    "    \n",
    "# Save:\n",
    "ds_bio10 = xr.concat(ds_bio10, dim=\"year\")\n",
    "ds_bio10.to_netcdf(\"./datasets/bio10.nc\")\n",
    "\n",
    "ds_bio11 = xr.concat(ds_bio11, dim=\"year\")\n",
    "ds_bio11.to_netcdf(\"./datasets/bio11.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1ed02",
   "metadata": {},
   "source": [
    "# [BIO12] Annual Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio12 = prec_mtot.groupby(\"Time.year\").sum(dim=\"Time\")\n",
    "ds_bio12.to_netcdf(\"./datasets/bio12.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf18bc",
   "metadata": {},
   "source": [
    "# [BIO13] Precipitation of Wettest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio13 = prec_mtot.groupby(\"Time.year\").max(dim=\"Time\")\n",
    "ds_bio13.to_netcdf(\"./datasets/bio13.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98b49f",
   "metadata": {},
   "source": [
    "# [BIO14] Precipitation of Driest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274cb04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio14 = prec_mtot.groupby(\"Time.year\").min(dim=\"Time\")\n",
    "ds_bio14.to_netcdf(\"./datasets/bio14.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af888071",
   "metadata": {},
   "source": [
    "# [BIO15] Precipitation Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd75b7",
   "metadata": {},
   "source": [
    "Precipitation seasonality in a given year is defined as: \n",
    "$$\n",
    "\\frac{\\sigma(P_i)}{1 + \\text{BIO12}\\,/\\,12} \\cdot 100 \\quad \\text{for}\\, i \\in [1,12]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb612975",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio15 = prec_mtot.groupby(\"Time.year\").std(dim=\"Time\") / (1. + ds_bio12/12.) * 100\n",
    "ds_bio15.to_netcdf(\"./datasets/bio15.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9897d91",
   "metadata": {},
   "source": [
    "# [BIO16/17] Precipitation of Wettest/Driest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a621fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio16 = []\n",
    "ds_bio17 = []\n",
    "\n",
    "for year in set(dstime[\"Time.year\"].values):\n",
    "    precip_quarterly = [] #mean\n",
    "    \n",
    "    # For each year loop through all the quarters as defined in description of BIO8:\n",
    "    start_dates = np.arange(np.datetime64(f\"{year}-01\"), np.datetime64(f\"{year+1}-01\"), np.timedelta64(1, \"M\"))\n",
    "    for start_date in start_dates:\n",
    "        slice_quart = slice(start_date, start_date + np.timedelta64(2, \"M\")) #quarter as time slice\n",
    "        \n",
    "        precip_quarterly.append(prec_mtot.sel(Time=slice_quart).sum(dim=\"Time\")) #total precipitation per grid point\n",
    "        \n",
    "    ds_bio16.append(xr.concat(precip_quarterly, dim=\"Quarter\").max(dim=\"Quarter\"))\n",
    "    ds_bio17.append(xr.concat(precip_quarterly, dim=\"Quarter\").min(dim=\"Quarter\"))\n",
    "\n",
    "    \n",
    "# Save:\n",
    "ds_bio16 = xr.concat(ds_bio16, dim=\"year\")\n",
    "ds_bio16.to_netcdf(\"./datasets/bio16.nc\")\n",
    "\n",
    "ds_bio17 = xr.concat(ds_bio17, dim=\"year\")\n",
    "ds_bio17.to_netcdf(\"./datasets/bio17.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8b7a9",
   "metadata": {},
   "source": [
    "# [BIO18/19] Precipitation of Warmest/Coldest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb850d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio18 = []\n",
    "ds_bio19 = []\n",
    "\n",
    "for year in set(dstime[\"Time.year\"].values):\n",
    "    tas_quarterly = [] #mean\n",
    "    precip_quarterly = [] #total\n",
    "    \n",
    "    # For each year loop through all the quarters as defined above:\n",
    "    start_dates = np.arange(np.datetime64(f\"{year}-01\"), np.datetime64(f\"{year+1}-01\"), np.timedelta64(1, \"M\"))\n",
    "    for start_date in start_dates:\n",
    "        slice_quart = slice(start_date, start_date + np.timedelta64(2, \"M\")) #quarter as time slice\n",
    "        \n",
    "        tas_quarterly.append(tas_mmean.sel(Time=slice_quart).mean(dim=\"Time\")) #mean temperature per grid point\n",
    "        precip_quarterly.append(prec_mtot.sel(Time=slice_quart).sum(dim=\"Time\")) #total precipitation per grid point\n",
    "    \n",
    "    # Get indices of warmest quarters this year:\n",
    "    tas_quarterly = xr.concat(tas_quarterly, dim=\"Quarter\")\n",
    "    warmest_quarters = tas_quarterly.argmax(dim=\"Quarter\")\n",
    "    coldest_quarters = tas_quarterly.argmin(dim=\"Quarter\")\n",
    "    \n",
    "    # Get precipitation in warmest quarters:\n",
    "    precip_quarterly = xr.concat(precip_quarterly, dim=\"Quarter\")\n",
    "    ds_bio18.append(precip_quarterly.isel(Quarter=warmest_quarters))\n",
    "    ds_bio19.append(precip_quarterly.isel(Quarter=coldest_quarters))\n",
    "    \n",
    "    \n",
    "# Save:\n",
    "ds_bio18 = xr.concat(ds_bio18, dim=\"year\")\n",
    "ds_bio18.to_netcdf(\"./datasets/bio18.nc\")\n",
    "\n",
    "ds_bio19 = xr.concat(ds_bio19, dim=\"year\")\n",
    "ds_bio19.to_netcdf(\"./datasets/bio19.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99e7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
